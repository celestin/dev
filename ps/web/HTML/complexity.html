<HTML><HEAD><TITLE>Complexity Metrics and Models</TITLE></HEAD>
<BODY vLink=purple link=blue>
<H1>Complexity Metrics and Models </H1>
<CENTER>
<TABLE width=0%>
  <TBODY>
  <TR>
    <TD width="90%" bgColor=#f0f0f0
valing="top"></TD></TR></TBODY></TABLE></CENTER><A name=halstead>
<P><STRONG>Halstead's Software
Science</STRONG><BR>
<BLOCKQUOTE>
  <P>The Software Science [Halstead 77] developed by M.H.Halstead principally
  attempts to estimate the programming effort. </P>
  <P>The measurable and countable properties are :
  <UL>
    <LI>n<SUB>1</SUB> = number of unique or distinct operators appearing in that
    implementation
    <LI>n<SUB>2</SUB> = number of unique or distinct operands appearing in that
    implementation
    <LI>N<SUB>1</SUB> = total usage of all of the operators appearing in that
    implementation
    <LI>N<SUB>2</SUB> = total usage of all of the operands appearing in that
    implementation </LI></UL>From these metrics Halstead defines :
  <OL type=i>
    <LI>the vocabulary n as n = n<SUB>1</SUB> + n<SUB>2</SUB>
    <LI>the implementation length N as N = N<SUB>1</SUB> + N<SUB>2</SUB>
  </LI></OL>Operators can be "+" and "*" but also an index "[...]" or a
  statement separation "..;..". The number of operands consists of the numbers
  of literal expressions, constants and variables.
  <P></P>
  <P><FONT size=5>Length Equation</FONT><BR>It may be necessary to know about
  the relationship between length N and vocabulary n. <B>Length Equation</B> is
  as follows. " ' " on N means it is calculated rather than counted :
  <BR><BR><FONT size=5>N ' = n<SUB>1</SUB><I>log</I><SUB>2</SUB>n<SUB>1</SUB> +
  n<SUB>2</SUB><I>log</I><SUB>2</SUB>n<SUB>2</SUB> </FONT><BR><BR>It is
  experimentally observed that N ' gives a rather close agreement to program
  length. </P>
  <P><FONT size=5>Quantification of Intelligence Content</FONT><BR>The same
  algorithm needs more consideration in a low level programming language. It is
  easier to program in Pascal rather than in assembly. The intellegence Content
  determines how much is said in a program.<BR><BR>In order to find
  Quantification of Intelligence Content we need some other metrics and formulas
  :<BR><BR><B>Program Volume </B>: This metric is for the size of any
  implementation of any algorithm.<BR><BR><FONT size=5>V =
  Nlog<SUB>2</SUB>n</FONT><BR><BR><B>Program Level </B>: It is the relationship
  between <I>Program Volume</I> and <I>Potential Volume</I>. Only the most clear
  algorithm can have a level of unity.<BR><BR><FONT size=5>L = V<SUP>*</SUP> / V
  </FONT><BR><BR><B>Program Level Equation</B> : is an approximation of the
  equation of the <I>Program Level</I>. It is used when the value of
  <I>Potential Volume</I> is not known because it is possible to measure it from
  an implementation directly.<BR><BR><FONT size=5>L ' =
  n<SUP>*</SUP><SUB>1</SUB>n<SUB>2</SUB> / n<SUB>1</SUB>N<SUB>2</SUB>
  </FONT><BR><BR><B>Intelligence Content</B><BR><BR><FONT size=5>I = L ' x V = (
  2n<SUB>2</SUB> / n<SUB>1</SUB>N<SUB>2</SUB> ) x (N<SUB>1</SUB> +
  N<SUB>2</SUB>)log<SUB>2</SUB>(n<SUB>1</SUB> + n<SUB>2</SUB>) </FONT><BR><BR>In
  this equation all terms on the right-hand side are directly measurable from
  any expression of an algorithm. The intelligence content is correlated highly
  with the potential volume. Consequently, because potential volume is
  independent of the language, the intelligence content should also be
  independent. </P><FONT size=5>Programming Effort</FONT><BR>
  <P>The programming effort is restricted to the mental activity required to
  convert an existing algorithm to an actual implementation in a programming
  language.<BR>In order to find <I>Programming effort</I> we need some metrics
  and formulas : <BR><BR><B>Potential Volume</B> : is a metric for denoting the
  corresponding parameters in an algorithm's shortest possible form. Neither
  operators nor operands can require repetition. <BR><BR><FONT size=5>V ' = (
  n<SUP>*</SUP><SUB>1</SUB> + n<SUP>*</SUP><SUB>2</SUB> ) log<SUB>2</SUB> (
  n<SUP>*</SUP><SUB>1</SUB> + n<SUP>*</SUP><SUB>2</SUB> )
  </FONT><BR><BR><B>Effort Equation</B><BR>The total number of elementary mental
  discriminations is : <BR><BR><FONT size=5>E = V / L = V<SUP>2</SUP> / V '
  </FONT><BR><BR>If we express it : The implementation of any algorithm consists
  of N <I>selections</I> ( nonrandom &gt; of a vocabulary n. a program is
  generated by making as many mental comparisons as the program volume equation
  determines, because the program volume V is a measure of it. Another aspect
  that influences the effort equation is the program difficulty. Each mental
  comparison consists of a number of elementary mental discriminations. This
  number is a measure for the program difficulty. <BR><BR><B>Time
  Equation</B><BR>A concept concerning the processing rate of the human brain,
  developed by the psychologist John Stroud, can be used. Stroud defined a
  moment as the time required by the human brain to perform the most elementary
  discrimination. The Stroud number S is then Stroud's moments per second with 5
  &lt;= S &lt;= 20. Thus we can derive the time equation where, except for the
  Stroud number S, all of the parameters on the right are directly measurable :
  <BR><BR><FONT size=5>T ' = ( n<SUB>1</SUB>N<SUB>2</SUB>(
  n<SUB>1</SUB><I>log</I><SUB>2</SUB>n<SUB>1</SUB> +
  n<SUB>2</SUB><I>log</I><SUB>2</SUB>n<SUB>2</SUB>) <I>log</I><SUB>2</SUB>n) /
  2n<SUB>2</SUB>S </FONT><BR><BR></P><STRONG>Advantages of Halstead :</STRONG>
  <OL type=i>
    <LI>Do not require in-depth analysis of programming structure.
    <LI>Predicts rate of error.
    <LI>Predicts maintenance effort.
    <LI>Useful in scheduling and reporting projects.
    <LI>Measure overall quality of programs.
    <LI>Simple to calculate.
    <LI>Can be used for any programming language.
    <LI>Numerous industry studies support the use of Halstead in predicting
    programming effort and mean number of programming bugs.
  </LI></OL><STRONG>Drawbacks of Halstead : </STRONG>
  <OL type=i>
    <LI>It depends on completed code.
    <LI>It has little or no use as a predictive estimating model. But McCabe's
    model is more suited to application at the design level.
</LI></OL></BLOCKQUOTE><A name=mccabe>
<P><STRONG>McCabe's Cyclomatic
number</STRONG><BR></P>
<BLOCKQUOTE>A measure of the complexity of a program was developed by [McCabe 1976]. He
  developed a system which he called the cyclomatic complexity of a program.
  This system measures the number of independent paths in a program, thereby
  placing a numerical value on the complexity. In practice it is a count of the
  number of test conditions in a program.
  <P>The cyclomatic complexity (CC) of a graph (G) may be computed according to
  the following formula:
  <P align=center>CC(G) = Number (edges) - Number (nodes) + 1 </P>
  <P>The results of multiple experiments (G.A. Miller) suggest that modules
  approach zero defects when McCabe's Cyclomatic Complexity is within 7 ± 2.
  <BR><BR>A study of PASCAL and FORTRAN programs (Lind and Vairavan 1989) found
  that a Cyclomatic Complexity between 10 and 15 minimized the number of module
  changes. </P>
  <P>There are some other metrics that are inspritted from cyclomatic complexity.</P>

  <STRONG>Advantages of McCabe Cyclomatic Complexity : </STRONG>
  <OL type=i>
    <LI>It can be used as a ease of maintenance metric.
    <LI>Used as a quality metric, gives relative complexity of various designs.
    <LI>It can be computed early in life cycle than of Halstead's metrics.
    <LI>Measures the minimum effort and best areas of concentration for testing.

    <LI>It guides the testing process by limiting the program logic during
    development.
    <LI>Is easy to apply. </LI></OL><STRONG>Drawbacks of McCabe Cyclomatic
  Complexity : </STRONG>
  <OL type=i>
    <LI>The cyclomatic complexity is a measure of the program's control
    complexity and not the data complexity
    <LI>the same weight is placed on nested and non-nested loops. However,
    deeply nested conditional structures are harder to understand than
    non-nested structures.
    <LI>It may give a misleading figure with regard to a lot of simple
    comparisons and decision structures. Whereas the fan-in fan-out method would
    probably be more applicable as it can track the data flow
</LI></OL></BLOCKQUOTE><STRONG>Fan-In Fan-Out
Complexity - Henry's and Kafura's</STRONG><BR>
<BLOCKQUOTE>
  <P>Henry and Kafura (1981) [from
  Sommerville 1992] identified a form of the fan in - fan out complexity
  which maintains a count of the number of data flows from a component plus the
  number of global data structures that the program updates. The data flow count
  includes updated procedure parameters and procedures called from within a
  module.
  <P align=center>Complexity = Length x (Fan-in x Fan-out)<SUP>2</SUP>
  <CENTER></CENTER>
  <P></P>
  <P>Length is any measure of length such as lines of code or alternatively
  McCabe's cyclomatic complexity is sometimes substituted. </P>
  <P>Henry and Kafura validated their me tric using the UNIX system and
  suggested that the measured complexity of a component allowed potenetially
  faulty system components to be identified. They found that high values of this
  metric were often measured in components where there had historically been a
  high number of problems. </P><STRONG>Advantages of Henry's and Kafura's
  Metic</STRONG>
  <OL type=i>
    <LI>it takes into account data-driven programs
    <LI>it can be derived prior to coding, during the design stage
  </LI></OL><STRONG>Drawbacks of Henry's and Kafura's Metic</STRONG>
  <OL type=i>
    <LI>it can give complexity values of zero if a procedure has no external
    interactions </LI></OL>
  <P></P></BLOCKQUOTE>
<CENTER>
